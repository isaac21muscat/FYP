{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import signal\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper:\n",
    "    def __init__(self, folder_name = 'data'):\n",
    "        self.CHROME_DRIVER_PATH = \".\\chromedriver_win32\\chromedriver.exe\"\n",
    "        # self.GECKO_DRIVER_PATH  = os.path.join('..','geckodriver')\n",
    "                                               \n",
    "        self.NEWS_IMG_PATH = os.path.join(folder_name, 'img')\n",
    "        self.NEWS_PATH = folder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "### STEP 1\n",
    "- Contents CSV 1 (Image Name, Caption, Inset Boolean)\n",
    "- Contents CSV 2 (Article URL, Article Name, Categories, Date, List of Image Names)\n",
    "- Draw ERD\n",
    "\n",
    "### STEP 2\n",
    "- Get most recent articles (example: past week or past 100 articles)\n",
    "- Perform same functionality as in step 1\n",
    "- Calculate statistics (To be discussed in further detail)\n",
    "\n",
    "### STEP 3\n",
    "- Research Image-in-Image and Picture-in-Picture Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: History - The canal/tunnel proposals to connect Grand Harbour and Marsamxett\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "5 columns passed, passed data had 4 columns\n",
      "Error: Reloading page 3\n",
      "Title: The week at a glance\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "5 columns passed, passed data had 4 columns\n",
      "Error: Reloading page 5\n",
      "Title: Sharing local memories of two canonised pontiffs\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "Saving...\n",
      "\n",
      "5 columns passed, passed data had 4 columns\n",
      "Error: Reloading page 7\n",
      "Title: Improving literacy through play\n",
      "Saving...\n",
      "\n",
      "5 columns passed, passed data had 4 columns\n",
      "Error: Reloading page 9\n",
      "Error: Reloading page 10\n",
      "Error: Reloading page 11\n"
     ]
    }
   ],
   "source": [
    "m = WebScraper(folder_name = '.\\\\times_of_malta')\n",
    "\n",
    "# def signal_handler(sig, frame):\n",
    "#     pd.DataFrame(columns=['Title','Image Name','Caption','Body'], data=data).to_csv(os.path.join(m.NEWS_PATH,'data.csv'), index=False)\n",
    "#     sys.exit()\n",
    "\n",
    "def get_img_ext(img_link):\n",
    "    if img_link.endswith('.jpeg'):\n",
    "        return '.jpeg'\n",
    "    elif img_link.endswith('.jpg'):\n",
    "        return '.jpg'\n",
    "    elif img_link.endswith('.png'):\n",
    "        return '.png'\n",
    "    else: return \"\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "service = Service(executable_path=m.CHROME_DRIVER_PATH)\n",
    "\n",
    "# Since chromedriver is in PATH we dont have specify it location otherwise webdriver.Chrome('path/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service = service, options = options)\n",
    "\n",
    "# Opening required website to scrape content \n",
    "driver.get('https://timesofmalta.com/search?keywords=inset&author=0&tags=0&sort=date&order=desc&fields%5B0%5D=title&fields%5B1%5D=body&page=1')\n",
    "\n",
    "\n",
    "#Closing pop-ups\n",
    "# print('Closing initial pop-ups: ',end='')\n",
    "# driver.find_element(By.XPATH,'/html/body/div[4]/div[2]/div[1]/div[2]/div[2]/button[1]').click()\n",
    "# print('[OK]')\n",
    "\n",
    "\n",
    "data = []\n",
    "count = 0\n",
    "article_index = 0\n",
    "page_index = 0\n",
    "\n",
    "#Setup ^C Handler to save on signal.\n",
    "try: \n",
    "    # print(driver.find_element(By.CLASS_NAME,'fc-button fc-cta-consent fc-primary-button'))\n",
    "    # print(\"FOUND BUT NOT CLICKED\")\n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \n",
    "                                                                \"//div[@class='fc-consent-root']//button[@aria-label='Consent']//p[@class='fc-button-label' and text()='Consent']\"))).click()\n",
    "    #driver.find_element(By.CLASS_NAME,\"fc-button fc-cta-consent fc-primary-button\").click()\n",
    "except: \n",
    "    pass\n",
    "for i in range(10):\n",
    "\n",
    "    # signal.signal(signal.SIGINT, signal_handler)\n",
    "    try: \n",
    "        #Remove donation message\n",
    "        try: driver.find_element(By.XPATH,'//*[@id=\"eng-accept\"]').click()\n",
    "        except: pass\n",
    "\n",
    "        #Click on article\n",
    "        driver.find_element(By.XPATH,f'//*[@id=\"listing-articles\"]/div[{str(2+article_index)}]/a').click()\n",
    "        #Increment article index\n",
    "        article_index += 1\n",
    "\n",
    "        sleep(1)\n",
    "\n",
    "        url = driver.current_url\n",
    "        #Get Title\n",
    "        title = driver.find_element(By.XPATH,'//*[@id=\"article-head\"]/div/h1').text\n",
    "\n",
    "        print(f'Title: {title}')\n",
    "        \n",
    "        #Get Thumbnail + Images\n",
    "        img_links = [img for img in \\\n",
    "                     driver.find_elements(By.XPATH,'//*[@id=\"observer\"]/main/article/div[2]/div/*/img') +\\\n",
    "                     driver.find_elements(By.XPATH,'//*[@id=\"article-head\"]/div/picture/img')]\n",
    "        \n",
    "        captions = \"\"\n",
    "        images   = \"\"\n",
    "\n",
    "        #Write images to disk\n",
    "        for img_link in img_links:\n",
    "            img_src   = img_link.get_attribute('src')        #Get source\n",
    "            captions  = img_link.get_attribute('alt') + 'â˜º' #Append current caption\n",
    "\n",
    "            img_ext  = get_img_ext(img_src)                #Get image extension\n",
    "            img_name = f'img{str(count).zfill(5)}'+img_ext #Get image name\n",
    "            images  = img_name + ','                      #Append image name to list\n",
    "            img_data = requests.get(img_src).content       #Download image\n",
    "\n",
    "            insetBool = \"NO\"\n",
    "            if \"inset\" in captions or \"Inset\" in captions:\n",
    "                insetBool = \"YES\"\n",
    "            data.append([url, images[:-1], captions[:-1], insetBool])\n",
    "            print('Saving...\\n')\n",
    "            pd.DataFrame(columns=['URL', 'Image Name', 'Caption', 'Inset'], data=data).to_csv(os.path.join(m.NEWS_PATH,'Article_Information.csv'), index=False)\n",
    "            count += 1\n",
    "\n",
    "            \n",
    "            #Write current image to disk\n",
    "            with open(os.path.join(m.NEWS_IMG_PATH,img_name),'wb') as f:\n",
    "                f.write(img_data)\n",
    "\n",
    "        #Get Body\n",
    "        text_content = driver.find_element(By.XPATH,'//*[@id=\"observer\"]/main/article/div[2]/div')                                                     \n",
    "        body = \" \".join(p.text for p in text_content.find_elements(By.TAG_NAME,'p'))\n",
    "\n",
    "        #Add row\n",
    "        #pd.DataFrame(columns=['URL', 'Article Name', 'Categories', 'Date', 'Images'], data=data).to_csv(os.path.join(m.NEWS_PATH,'Image_Information.csv'), index=False)\n",
    "\n",
    "        #Save to csv\n",
    "        # if i%50 == 0:\n",
    "        \n",
    "\n",
    "    #Go back\n",
    "        print('Back to home page\\n')\n",
    "        driver.back()\n",
    "\n",
    "    except selenium.common.exceptions.NoSuchElementException as e:\n",
    "        #Switch to next page\n",
    "        sleep(1.5)\n",
    "\n",
    "        try: driver.find_element(By.XPATH,f'//*[@id=\"observer\"]/main/div/div[2]/div/span[{str(2+page_index)}]').click()\n",
    "        except: \n",
    "            print(f'Error: Reloading page {page_index+2}')\n",
    "            driver.get(f'https://google.com')\n",
    "            sleep(2)\n",
    "            page_index += 1\n",
    "            driver.get(f'https://timesofmalta.com/search?keywords=inset&author=0&tags=0&sort=date&order=desc&fields%5B0%5D=title&fields%5B1%5D=body&page={str(page_index+2)}') #Skip page\n",
    "\n",
    "            try: driver.find_element(By.XPATH,'//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]').click() #Close pop-up\n",
    "            except: pass\n",
    "\n",
    "            article_index = 0 #Invoke next-page switch\n",
    "            \n",
    "            continue #Go back to beggining\n",
    "\n",
    "        \n",
    "\n",
    "        page_index   += 1\n",
    "        article_index = 0\n",
    "        print(f'Next Page! -> {page_index+1}')\n",
    "    \n",
    "    except selenium.common.exceptions.ElementClickInterceptedException as e:\n",
    "        print('Click Intercepted - Skipping')\n",
    "        article_index += 1\n",
    "        continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        article_index += 1\n",
    "        page_index += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = WebScraper(folder_name = '.\\\\times_of_malta')\n",
    "\n",
    "# # def signal_handler(sig, frame):\n",
    "# #     pd.DataFrame(columns=['Title','Image Name','Caption','Body'], data=data).to_csv(os.path.join(m.NEWS_PATH,'data.csv'), index=False)\n",
    "# #     sys.exit()\n",
    "\n",
    "# def get_img_ext(img_link):\n",
    "#     if img_link.endswith('.jpeg'):\n",
    "#         return '.jpeg'\n",
    "#     elif img_link.endswith('.jpg'):\n",
    "#         return '.jpg'\n",
    "#     elif img_link.endswith('.png'):\n",
    "#         return '.png'\n",
    "#     else: return \"\"\n",
    "\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "# service = Service(executable_path=m.CHROME_DRIVER_PATH)\n",
    "\n",
    "# # Since chromedriver is in PATH we dont have specify it location otherwise webdriver.Chrome('path/chromedriver.exe')\n",
    "# driver = webdriver.Chrome(service = service, options = options)\n",
    "\n",
    "# # Opening required website to scrape content \n",
    "# driver.get('https://timesofmalta.com/search?keywords=inset&author=0&tags=0&sort=date&order=desc&fields%5B0%5D=title&fields%5B1%5D=body&page=1')\n",
    "\n",
    "\n",
    "# #Closing pop-ups\n",
    "# # print('Closing initial pop-ups: ',end='')\n",
    "# # driver.find_element(By.XPATH,'/html/body/div[4]/div[2]/div[1]/div[2]/div[2]/button[1]').click()\n",
    "# # print('[OK]')\n",
    "\n",
    "\n",
    "# data = []\n",
    "# count = 0\n",
    "# article_index = 0\n",
    "# page_index = 0\n",
    "\n",
    "# #Setup ^C Handler to save on signal.\n",
    "# try: \n",
    "#     # print(driver.find_element(By.CLASS_NAME,'fc-button fc-cta-consent fc-primary-button'))\n",
    "#     # print(\"FOUND BUT NOT CLICKED\")\n",
    "#     WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \n",
    "#                                                                 \"//div[@class='fc-consent-root']//button[@aria-label='Consent']//p[@class='fc-button-label' and text()='Consent']\"))).click()\n",
    "#     #driver.find_element(By.CLASS_NAME,\"fc-button fc-cta-consent fc-primary-button\").click()\n",
    "# except: \n",
    "#     pass\n",
    "# for i in range(10):\n",
    "\n",
    "#     # signal.signal(signal.SIGINT, signal_handler)\n",
    "#     try: \n",
    "#         #Remove donation message\n",
    "#         try: driver.find_element(By.XPATH,'//*[@id=\"eng-accept\"]').click()\n",
    "#         except: pass\n",
    "\n",
    "#         #Click on article\n",
    "#         driver.find_element(By.XPATH,f'//*[@id=\"listing-articles\"]/div[{str(2+article_index)}]/a').click()\n",
    "#         #Increment article index\n",
    "#         article_index += 1\n",
    "\n",
    "#         sleep(1)\n",
    "\n",
    "#         url = driver.current_url\n",
    "#         #Get Title\n",
    "#         title = driver.find_element(By.XPATH,'//*[@id=\"article-head\"]/div/h1').text\n",
    "\n",
    "#         print(f'Title: {title}')\n",
    "        \n",
    "#         #Get Thumbnail + Images\n",
    "#         img_links = [img for img in \\\n",
    "#                      driver.find_elements(By.XPATH,'//*[@id=\"observer\"]/main/article/div[2]/div/*/img') +\\\n",
    "#                      driver.find_elements(By.XPATH,'//*[@id=\"article-head\"]/div/picture/img')]\n",
    "        \n",
    "#         captions = \"\"\n",
    "#         images   = \"\"\n",
    "\n",
    "#         #Write images to disk\n",
    "#         for img_link in img_links:\n",
    "#             img_src   = img_link.get_attribute('src')        #Get source\n",
    "#             captions  += img_link.get_attribute('alt') + 'â˜º' #Append current caption\n",
    "\n",
    "#             img_ext  = get_img_ext(img_src)                #Get image extension\n",
    "#             img_name = f'img{str(count).zfill(5)}'+img_ext #Get image name\n",
    "#             images  += img_name + ','                      #Append image name to list\n",
    "#             img_data = requests.get(img_src).content       #Download image\n",
    "\n",
    "#             count += 1\n",
    "\n",
    "#             #Write current image to disk\n",
    "#             with open(os.path.join(m.NEWS_IMG_PATH,img_name),'wb') as f:\n",
    "#                 f.write(img_data)\n",
    "\n",
    "#         #Get Body\n",
    "#         text_content = driver.find_element(By.XPATH,'//*[@id=\"observer\"]/main/article/div[2]/div')                                                     \n",
    "#         body = \" \".join(p.text for p in text_content.find_elements(By.TAG_NAME,'p'))\n",
    "\n",
    "#         #Add row\n",
    "#         data.append([url, images[:-1], captions[:-1]])\n",
    "\n",
    "#         #Save to csv\n",
    "#         # if i%50 == 0:\n",
    "#         print('Saving...\\n')\n",
    "#         for image in images:\n",
    "#             pd.DataFrame(columns=['Image Name','Caption', 'Inset'], data=data).to_csv(os.path.join(m.NEWS_PATH,'contents.csv'), index=False)\n",
    "\n",
    "#     #Go back\n",
    "#         print('Back to home page\\n')\n",
    "#         driver.back()\n",
    "\n",
    "#     except selenium.common.exceptions.NoSuchElementException as e:\n",
    "#         #Switch to next page\n",
    "#         sleep(1.5)\n",
    "\n",
    "#         try: driver.find_element(By.XPATH,f'//*[@id=\"observer\"]/main/div/div[2]/div/span[{str(2+page_index)}]').click()\n",
    "#         except: \n",
    "#             print(f'Error: Reloading page {page_index+2}')\n",
    "#             driver.get(f'https://google.com')\n",
    "#             sleep(2)\n",
    "#             page_index += 1\n",
    "#             driver.get(f'https://timesofmalta.com/search?keywords=inset&author=0&tags=0&sort=date&order=desc&fields%5B0%5D=title&fields%5B1%5D=body&page={str(page_index+2)}') #Skip page\n",
    "\n",
    "#             try: driver.find_element(By.XPATH,'//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]').click() #Close pop-up\n",
    "#             except: pass\n",
    "\n",
    "#             article_index = 0 #Invoke next-page switch\n",
    "            \n",
    "#             continue #Go back to beggining\n",
    "\n",
    "        \n",
    "\n",
    "#         page_index   += 1\n",
    "#         article_index = 0\n",
    "#         print(f'Next Page! -> {page_index+1}')\n",
    "    \n",
    "#     except selenium.common.exceptions.ElementClickInterceptedException as e:\n",
    "#         print('Click Intercepted - Skipping')\n",
    "#         article_index += 1\n",
    "#         continue\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "#         article_index += 1\n",
    "#         page_index += 1\n",
    "#         continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
